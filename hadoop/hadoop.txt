--hadoop环境配置

--安装JDK
目录 usr/java
tar -zxvf 解压
--配置JDK环境变量
cd /etc/profile.d
新建java.sh
vi java.sh
JAVA_HOME=/usr/java/jdk1.8.0_121
CLASSPATH=$JAVA_HOME/lib:$CLASSPATH
PATH=$JAVA_HOME/bin:$PATH
export JAVA_HOME CLASSPATH PATH
--使变量生效
source /etc/profile.d/java.sh

--修改host
vi /etc/hosts
添加IP与机器名的关系
192.168.80.129 linux01

添加用户组及用户 
groupadd hadoop
useradd -g hadoop hadoop

--查看防火墙
service iptables status
--关闭防火墙
chkconfig iptables off 永久性关闭
service iptables stop 重启后复原

--切换hadoop用户配置SSH无密码验证配置
su yinlue
创建.ssh目录
mkdir .ssh
生成秘钥
ssh-keygen -t rsa
--将公钥生成至认证文件里
cp id_rsa.pub authorized_keys

--退至/目录对.ssh目录赋予权限
chmod 700 .ssh
chmod 600 .ssh/*

--安装hadoop
--cd至/usr/java
--安装wget
yum -y install wget
--切换root用户在线下载hadoop安装包
wget http://hadoop.f.dajiangtai.com/hadoop2.2/hadoop-2.2.0-x64.tar.gz
--解压hadoop
tar zxvf XXX.tar
--修改名称为hadoop
--给hadoop用户赋予权限
chown -R hadoop:hadoop hadoop
--在java目录下创建hadoop三个目录
mkdir -p /data/dfs/name
mkdir -p /data/dfs/data
mkdir -p /data/tmp
--赋予hadoop用户权限
chown -R hadoop:hadoop hadoop /data
--切换hadoop用户
su hadoop
cd hadoop/etc/hadoop
--修改core-site.xml配置文件
添加
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://linux01:9000</value>
	</property>

	<property>
		<name>hadoop.tmp.dir</name>				<value>file:/usr/local/hadoop/bigdata/tmp</value>
	</property> 

	<property>
		<name>hadoop.proxyuser.hadoop.hosts</name>
		<value>*</value>
	</property>

	<property>
		<name>hadoop.proxyuser.hadoop.groups</name>
		<value>*</value>
	</property>

--修改hdfs-site.xml
添加
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/usr/local/hadoop/bigdata/dfs/name</value>
		<final>true</final>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/usr/local/hadoop/bigdata/dfs/data</value>
		<final>true</final>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.permissions</name>
		<value>false</value>
	</property>
--修改mapred-site.xml文件
cp mapred-site.xml.template mapred-site.xml
添加
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
--修改yarn.site.xml
添加
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
--修改slaves
linux01

--设置hadoop环境变量
su root
vi /etc/profile
添加
HADOOP_HOME=/usr/java/hadoop
PATH=$HADOOP_HOME/bin:$PATH
export HADOOP_HOME PATH
--使配置文件生效
source /etc/profile
--切换hadoop
su hadoop
cd hadoop
--格式化namenode
bin/hadoop namenode -format
--查看进程
jps
--启动hadoop集群
sbin/start-all.sh


--在windows配置host与IP的对应关系
以管理员身份修改
反问：http://linux01:50070/

--wordCout测试
在hadoop目录下新建djt.txt
查看hdfs目录
hadoop fs -ls /
如果没有则创建dajiangtai目录
hadoop fs -mkdir /dajiangtai
上传新建的djt.txt
hadoop fs -put /usr/java/hadoop/djt.txt /dajiangtai
成功后反问
http://linux01:8088/cluster/apps
在hadoop目录下执行wordcount程序
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /dajiangtai/djt.txt /dajiangtai/wordcount-out
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount /profile /out
--查看运行结果
http://linux01:50070

--查看hadoop版本
hadoop version